# -*- coding: utf-8 -*-
"""Shap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wU5b0ywa5FF_6mBeOuIW2p9noNw_le98
"""

import os
import numpy as np
import cv2
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from google.colab import drive

drive.mount('/content/drive')

import os
import cv2
import numpy as np
import tensorflow as tf

# Define constants
image_size = 150
labels = ['glioma', 'meningioma', 'notumor', 'pituitary']
X_data = []
Y_data = []

# Use generator-style approach to avoid loading all at once
def load_images_in_batches(base_path, labels, image_size, max_images_per_class=500):
    X = []
    Y = []
    for label in labels:
        count = 0
        for folder in ['Training', 'Testing']:
            folder_path = os.path.join(base_path, folder, label)
            files = os.listdir(folder_path)
            for file in files:
                if count >= max_images_per_class:
                    break
                img_path = os.path.join(folder_path, file)
                img = cv2.imread(img_path)
                if img is not None:
                    img = cv2.resize(img, (image_size, image_size))
                    X.append(img / 255.0)  # Normalize on the fly
                    Y.append(labels.index(label))
                    count += 1
    return np.array(X, dtype=np.float32), tf.keras.utils.to_categorical(Y, num_classes=len(labels))

# Path to your dataset
base_path = '/content/drive/MyDrive/Brain tumar'

# Load limited number of images per class to avoid RAM crash
X_data, Y_data = load_images_in_batches(base_path, labels, image_size, max_images_per_class=500)

X_data, Y_data = shuffle(X_data, Y_data, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.1, random_state=42)

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.3))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Dropout(0.3))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.3))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.3))
model.add(Conv2D(128, (3, 3), activation='relu', name='last_conv'))  # Name this for Grad-CAM
model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(4, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

history = model.fit(X_train, y_train, epochs=10, validation_split=0.1)

plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss')
plt.legend()
plt.show()

# === 8. Install and Use SHAP ===
!pip install shap
import shap
from shap.maskers import Image as shap_Image

# Prepare background and test samples for SHAP
background = X_train[np.random.choice(X_train.shape[0], 50, replace=False)]
test_images = X_test[:5]

# ✅ Create SHAP masker with correct syntax (use image shape, not data!)
masker = shap_Image("inpaint_telea", test_images[0].shape)

# ✅ Create SHAP explainer
explainer = shap.Explainer(model, masker, output_names=labels)

# ✅ Compute SHAP values
shap_values = explainer(test_images)

# ✅ Plot SHAP image explanations
shap.image_plot(shap_values, test_images)

# === 9. Predict and Explain a Specific Image ===
from tensorflow.keras.preprocessing import image

img_path = '/content/drive/MyDrive/Brain tumar/Testing/meningioma/Te-me_0026.jpg'
img = cv2.imread(img_path)
img = cv2.resize(img, (150,150))
img = img / 255.0
img_array = img.reshape(1, 150, 150, 3)

# Predict class
prediction = model.predict(img_array)
predicted_label = labels[np.argmax(prediction)]
print("Predicted Tumor Type:", predicted_label)

# === SHAP explanation for this image ===
import shap
from shap.maskers import Image as shap_Image

# Step 1: Define the masker correctly — use "inpaint_telea" and the image shape
masker = shap_Image("inpaint_telea", img_array[0].shape)  # shape: (150, 150, 3)

# Step 2: Create the SHAP explainer
explainer_single = shap.Explainer(model, masker, output_names=labels)

# Step 3: Compute SHAP values for the single image
shap_value_single = explainer_single(img_array)

# Step 4: Plot SHAP explanation
shap.image_plot(shap_value_single, img_array)